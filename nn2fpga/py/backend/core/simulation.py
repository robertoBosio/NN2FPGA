from qonnx.core.modelwrapper import ModelWrapper
from qonnx.core.onnx_exec import execute_onnx
from qonnx.custom_op.registry import getCustomOp
from onnx import NodeProto
import numpy as np
import base64
import json
import os
import subprocess
from csnake import CodeWriter, Variable, Function

def dump_tcl_script(top_name, part_name, frequency, hls_version, input_files):
    """Dump a TCL script to set up the HLS project and run the simulation."""

    argv = " ".join(input_files)
    tb_files = " ".join(input_files + ["testbench.cpp"])
    t_clk = f"{1e3 / int(frequency):.2f}ns" # Convert frequency in MHz to clock period in ns
    lines = list()
    lines.append("# Auto-generated TCL script for HLS project setup")
    lines.append("# Generated by nn2fpga simulation flow")
    lines.append("")

    # Check the HLS version to determine the correct syntax
    if float(hls_version) > 2025:
        lines.append(
            'open_component -reset "proj_{top_name}" -flow_target vivado',
        )
    else:
        lines.extend(
            [
                'open_project -reset "proj_{top_name}"',
                'open_solution -reset solution0',
            ]
        )

    lines.extend(
        [
            'add_files kernel.cpp -cflags " -I/workspace/NN2FPGA/nn2fpga/library/include"',
            'add_files -tb "/workspace/NN2FPGA/deps/cnpy/cnpy.cpp"',
            'add_files -tb "{tb_files}" -cflags "-I/workspace/NN2FPGA/deps/cnpy -I/workspace/NN2FPGA/nn2fpga/library/include -lz"',
            'set_top "{top_name}"',
            'set_part {part_name}',
            'create_clock -period {t_clk}',
            'csim_design -argv "{argv}"',
            'csynth_design',
            'cosim_design -argv "{argv}"',
            'exit',
        ]
    )

    return "\n".join(lines).format(
        top_name=top_name, tb_files=tb_files, part_name=part_name, t_clk=t_clk, argv=argv
    )


def dump_testbench(top_name: str, input_names: list, output_names: list) -> str:

    cwr = CodeWriter()
    cwr.add_autogen_comment()

    # Include sections for HLS
    cwr.include("ap_int.h")
    cwr.include("hls_stream.h")
    cwr.include("ap_axi_sdata.h")
    cwr.include("nn2fpga/utils.h")

    kernel_function = Function(
        name=top_name,
        return_type="void",
        qualifiers=["extern"],
    )

    for name in [*input_names, *output_names]:
        kernel_function.add_argument(Variable(name, "hls::stream<ap_axiu<128, 0, 0, 0>>&"))

    cwr.add_line()
    cwr.add_function_prototype(kernel_function)

    main_function = Function(
        name="main",
        return_type="int",
        arguments=[Variable("argc", "int"), Variable("argv", "char**")],
    )

    main_function.add_code("")
    main_function.add_code("// Read input files and convert to HLS streams.")
    for i, var_name in enumerate([*input_names, *output_names]):
        main_function.add_code(f"std::string {var_name}_file = argv[{i + 1}];")

    for var_name in [*input_names, *output_names]:
        main_function.add_code(f"hls::stream<ap_uint<8>> {var_name}_stream;")

    for var_name in input_names:
        main_function.add_code(
            f"nn2fpga::npy_to_hls_stream<ap_uint<8>>({var_name}_file, {var_name}_stream);"
        )

    function_args = [f"{var_name}_stream" for var_name in [*input_names, *output_names]]
    print(f"Function args: {function_args}")
    main_function.add_code("// Call the accelerator kernel")
    main_function.add_code(f"{kernel_function.generate_call(*function_args)};")
    main_function.add_code("// Write output streams to files.")

    for var_name in output_names:
        main_function.add_code(
            f"nn2fpga::hls_stream_to_npy<ap_uint<8>>({var_name}_file, {var_name}_stream);"
        )

    main_function.add_code("return 0;")

    cwr.add_line()
    cwr.add_function_definition(main_function)
    return cwr.code

def make_build_dir(work_dir: str) -> None:
    """Create the working directory for the simulation."""
    os.makedirs(work_dir, exist_ok=True)

def simulate(blob: str, context: dict) -> dict:

    json_blob = json.loads(blob)
    work_dir = json_blob["work_dir"]
    work_dir = f"{os.path.abspath(work_dir)}/sim"
    make_build_dir(work_dir)
    internal_context = list()
    input_list = list()
    output_list = list()

    # Update the context with the input map
    input_map = json_blob["input_map"]
    for old_name, new_name in input_map.items():
        if old_name in context:
            internal_context.append((new_name, context[old_name]))
    input_list.extend(sorted(input_map.values()))

    # Save the value of the constant inputs
    for tensor_name, tensor_data in json_blob["constant_inputs"].items():
        tensor = np.frombuffer(
            base64.b64decode(tensor_data["data_b64"]), dtype=tensor_data["dtype"]
        ).reshape(tensor_data["shape"])
        internal_context.append((tensor_name, tensor))
    input_list.extend(
        sorted(tensor_name for tensor_name in json_blob["constant_inputs"].keys())
    )

    # Update the context with the output map
    output_map = json_blob["output_map"]
    for old_name, new_name in output_map.items():
        if old_name in context:
            internal_context.append((new_name, context[old_name]))
    output_list.extend(sorted(output_map.values()))

    # Save to file the internal context
    for tensor_name, tensor_data in internal_context:
        np.save(f"{work_dir}/{tensor_name}.npy", tensor_data)

    # Generate the TCL script
    tcl_script = dump_tcl_script(
        top_name=json_blob["top_name"],
        part_name=json_blob["part_name"],
        frequency=json_blob["frequency"],
        hls_version=json_blob["hls_version"],
        input_files=[f"{work_dir}/{tensor_name}.npy" for tensor_name, _ in internal_context],
    )

    # Write the TCL script to a file
    with open(f"{work_dir}/setup.tcl", "w") as f:
        f.write(tcl_script)

    # Write the HLS code to a file
    with open(f"{work_dir}/kernel.cpp", "w") as f:
        f.write(base64.b64decode(json_blob["hls_code_b64"]).decode())

    # Generate the HLS driver code
    with open(f"{work_dir}/testbench.cpp", "w") as f:
        f.write(base64.b64decode(json_blob["hls_driver_b64"]).decode())

    # run the simulation
    # subprocess.run(
    #     ["vitis_hls", "-f", f"{work_dir}/setup.tcl"],
    #     cwd=work_dir,
    #     check=True
    # )

    # Read the output files and update the context
    for old_name, new_name in output_map.items():
        output_file = f"{work_dir}/{new_name}.npy"
        if os.path.exists(output_file):
            tensor_data = np.load(output_file)
            context[old_name] = tensor_data
        else:
            raise FileNotFoundError(f"Output file {output_file} not found.")

    return context
